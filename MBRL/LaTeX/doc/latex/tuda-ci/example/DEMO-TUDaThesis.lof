\babel@toc {english}{}\relax 
\babel@toc {english}{}\relax 
\babel@toc {english}{}\relax 
\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Overview of the DreamerV2 training pipeline. The world model learns to predict future states and rewards, enabling the actor-critic framework to optimize policies using imagined rollouts. Taken from Hafner et al.~\blx@tocontentsinit {0}\cite {hafner2021mastering}, Fig.~1.}}{13}{figure.caption.6}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Training schedule showing the alternating phases of world model training and policy optimization. The world model is retrained every 10 policy iterations using newly collected experience from the current policy.}}{31}{figure.caption.7}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
