\babel@toc {ngerman}{}\relax 
\babel@toc {ngerman}{}\relax 
\babel@toc {ngerman}{}\relax 
\contentsline {chapter}{List of Abbreviations}{9}{chapter*.5}%
\contentsline {chapter}{\numberline {1}Introduction}{10}{chapter.1}%
\contentsline {section}{\numberline {1.1}Motivation and Problem Statement}{10}{section.1.1}%
\contentsline {section}{\numberline {1.2}Research Questions and Objectives}{10}{section.1.2}%
\contentsline {section}{\numberline {1.3}Contributions}{11}{section.1.3}%
\contentsline {section}{\numberline {1.4}Thesis Structure}{11}{section.1.4}%
\contentsline {chapter}{\numberline {2}Background and Related Work}{12}{chapter.2}%
\contentsline {section}{\numberline {2.1}Reinforcement Learning Fundamentals}{12}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Model-Free vs. Model-Based Approaches}{12}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Sample Efficiency Challenges}{12}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Generalization Problems}{13}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Model-Based Reinforcement Learning}{13}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}World Model Learning}{13}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Planning with Learned Models}{13}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}DreamerV2 Architecture}{13}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}DreamerV2 TD Lambda Targets}{13}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}DreamerV2 Actor Loss}{14}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}DreamerV2 Critic Loss}{15}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}TD Lambda Targets}{16}{subsection.2.2.7}%
\contentsline {section}{\numberline {2.3}Object-Centric Representations}{16}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Limitations of Pixel-Based Representations}{16}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Object-Centric Learning Approaches}{16}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Relational Reasoning in RL}{16}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Current Limitations and Research Gaps}{16}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Lack of Integration Between Approaches}{16}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Misalignment Problems}{16}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Generalization Challenges}{16}{subsection.2.4.3}%
\contentsline {chapter}{\numberline {3}Methodology}{17}{chapter.3}%
\contentsline {section}{\numberline {3.1}Theoretical Framework}{17}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Object-Centric World Model Design}{17}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Integration Strategy with Model-Based RL}{17}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}Expected Benefits Analysis}{17}{subsection.3.1.3}%
\contentsline {section}{\numberline {3.2}Implementation Approach}{17}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Environment Selection (Atari Pong)}{17}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Object-Centric State Representation}{17}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}World Model Architecture Design}{17}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Experimental Design}{17}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Baseline Comparisons}{17}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Evaluation Metrics}{17}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Ablation Studies}{17}{subsection.3.3.3}%
\contentsline {chapter}{\numberline {4}Implementation}{18}{chapter.4}%
\contentsline {section}{\numberline {4.1}Environment and Setup}{19}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Pong Environment Characteristics}{19}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Object-Centric State Extraction}{19}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Frame Stacking and Preprocessing}{19}{subsection.4.1.3}%
\contentsline {section}{\numberline {4.2}World Model Architecture}{19}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}LSTM-Based World Model (PongLSTM)}{19}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Alternative Architectures Explored}{19}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}State Normalization and Stability}{19}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}Actor-Critic Integration}{19}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}DreamerV2-Style Actor-Critic}{19}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Policy Learning in Imagined Rollouts}{19}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}Lambda-Return Computation}{19}{subsection.4.3.3}%
\contentsline {section}{\numberline {4.4}Training Pipeline}{19}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Experience Collection}{19}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}World Model Training}{19}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Policy Optimization}{19}{subsection.4.4.3}%
\contentsline {chapter}{\numberline {5}Experiments and Results}{20}{chapter.5}%
\contentsline {section}{\numberline {5.1}Experimental Setup}{21}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Hyperparameters and Configuration}{21}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Hardware and Implementation Details}{21}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Evaluation Protocol}{21}{subsection.5.1.3}%
\contentsline {section}{\numberline {5.2}World Model Performance}{21}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Prediction Accuracy Analysis}{21}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Long-Term Rollout Quality}{21}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Model Stability Assessment}{21}{subsection.5.2.3}%
\contentsline {section}{\numberline {5.3}Policy Learning Results}{21}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Sample Efficiency Comparison}{21}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Final Performance Evaluation}{21}{subsection.5.3.2}%
\contentsline {subsection}{\numberline {5.3.3}Learning Curve Analysis}{21}{subsection.5.3.3}%
\contentsline {section}{\numberline {5.4}Ablation Studies}{21}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Impact of Object-Centric Representations}{21}{subsection.5.4.1}%
\contentsline {subsection}{\numberline {5.4.2}Architecture Component Analysis}{21}{subsection.5.4.2}%
\contentsline {subsection}{\numberline {5.4.3}Reward Function Design Effects}{21}{subsection.5.4.3}%
\contentsline {section}{\numberline {5.5}Visualization and Interpretability}{21}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Real vs. Model Comparison}{21}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Learned Representations Analysis}{21}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}Policy Behavior Visualization}{21}{subsection.5.5.3}%
\contentsline {chapter}{\numberline {6}Discussion}{22}{chapter.6}%
\contentsline {section}{\numberline {6.1}Analysis of Results}{23}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Strengths of the Proposed Approach}{23}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Limitations and Challenges}{23}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Comparison with Existing Methods}{23}{subsection.6.1.3}%
\contentsline {section}{\numberline {6.2}Technical Insights}{23}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}World Model Design Choices}{23}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Training Stability Issues}{23}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Reward Engineering Importance}{23}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Implications for Object-Centric RL}{23}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Benefits of Integration}{23}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Generalization Potential}{23}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Scalability Considerations}{23}{subsection.6.3.3}%
\contentsline {section}{\numberline {6.4}Future Research Directions}{23}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}More Complex Environments}{23}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Improved Object Discovery}{23}{subsection.6.4.2}%
\contentsline {subsection}{\numberline {6.4.3}Multi-Object Scenarios}{23}{subsection.6.4.3}%
\contentsline {chapter}{\numberline {7}Conclusion}{24}{chapter.7}%
\contentsline {section}{\numberline {7.1}Summary of Contributions}{24}{section.7.1}%
\contentsline {section}{\numberline {7.2}Key Findings}{24}{section.7.2}%
\contentsline {section}{\numberline {7.3}Limitations and Future Work}{24}{section.7.3}%
\contentsline {section}{\numberline {7.4}Final Remarks}{24}{section.7.4}%
\contentsline {chapter}{\numberline {A}Implementation Details}{25}{appendix.A}%
\contentsline {section}{\numberline {A.1}Code Structure and Organization}{25}{section.A.1}%
\contentsline {section}{\numberline {A.2}Hyperparameter Sensitivity Analysis}{25}{section.A.2}%
\contentsline {section}{\numberline {A.3}Additional Experimental Results}{25}{section.A.3}%
\contentsline {chapter}{\numberline {B}Technical Specifications}{26}{appendix.B}%
\contentsline {section}{\numberline {B.1}Hardware Requirements}{26}{section.B.1}%
\contentsline {section}{\numberline {B.2}Software Dependencies}{26}{section.B.2}%
\contentsline {section}{\numberline {B.3}Reproducibility Guidelines}{26}{section.B.3}%
\contentsline {chapter}{\numberline {C}Supplementary Figures and Tables}{27}{appendix.C}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
